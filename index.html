<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yongjie Zhu</title>
  
  <meta name="author" content="Yongjie Zhu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ai_icon.png">
  <script src="script/functions.js"></script> 
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yongjie Zhu</name>
              </p>
              <p>I am now an Algorithm Engineer at <a href="https://www.alibabagroup.com/">Alibaba Group</a> (Beijing), mentored by  <a href="https://byeah.github.io/">Biye Jiang</a>. I obtained my Master degree from School of Artificial Intelligence, <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications (BUPT)</a>, co-supervised by Prof. <a href="https://www.pris.net.cn/introduction/teacher/lisi">Si Li</a> and Prof. <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>. 
              <!-- <p>I am a third year Master student in the School of Artificial Intelligence at <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications (BUPT)</a>, supervised by Prof. <a href="https://www.pris.net.cn/introduction/teacher/lisi">Si Li</a> and Prof. <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>.  -->
              </p>
              <p>
                I was a research intern at <a href="https://en.wikipedia.org/wiki/Microsoft">Microsoft</a>, where I work on computer vision and natural language processing. I also worked as a research intern at Tencent, WXG. At Tencent I've worked on <a href="">3D Human Body Estimation</a> and <a href="">Face Appearance Modeling</a> under the guidance of Dr. <a href="https://www.lichenpro.com/">Chen Li</a>. Before that, I got my Bachelor degree at BUPT, advised by Prof. <a href="https://www.pris.net.cn/introduction/teacher/lisi">Si Li</a>. I've received the China National Scholarship and the JJWorld (Beijing) Network Technology Scholarship (top 3%) at BUPT. 
              </p>
              <p style="text-align:center">
                <a href="mailto:yongjie.zhu.96@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/YongjieZhu-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/YongjieZhu-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=AQLfp6cAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/yongjie-zhu-%E6%9C%B1%E5%8B%87%E6%9D%B0-38a145156/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/Yongjie-Zhu/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/YongjieZhu.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/YongjieZhu_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>



    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <heading>News</heading>
          <ul>
            <li><strong>[2022.07]</strong> One paper got accepted by <a href="https://eccv2022.ecva.net/">ECCV 2022</a>. </li> 
            <li><strong>[2022.06]</strong> <a href="">AdsCVLR</a> is accepted by <a href="https://2022.acmmm.org/">ACM MM 2022</a>. </li> 
            <li><strong>[2021.11]</strong> Received China National Scholarship. </li>
            <li><strong>[2021.05]</strong> <a href="http://cvpr2021.thecvf.com/node/184?fbclid=IwAR3zy5xnT4xm3v5uaF8DpUuOadKC0MsgM9sWE39iDivZoSaq0UtgMARFaiA">Outstanding reviewer</a> of <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>. </li>
            <li><strong>[2021.05]</strong> The extension of my bachelor thesis <a href="">HyFRIS-Net</a> got accepted by <a href="">TPAMI 2021</a>! </li>
                     
            
            <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
            <div id="old_news" style="display: none;">
               <li><strong>[2021.03]</strong>  <a href="https://arxiv.org/abs/2104.04160">SOLID-Net</a> is accepted by <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a> as <span style="color:#ff0000;"><strong>oral presentation</strong></span> <strong>(top 4%)</strong>!</li>
              <li><strong>[2021.03]</strong> <a href="https://arxiv.org/abs/2104.13602">DeRenderNet</a> is accepted by <a href="https://iccp-conference.org/">ICCP 2021</a>. </li>
            </div></div>
          </ul>
        </td>
      </tr>
      <!-- <tr> -->
      <!--   <td width="100%" valign="middle"> -->
      <!--     <heading>Research</heading> -->
      <!--   </td> -->
      <!-- </tr> -->
    </table> 
    
        <!-- <\!-- <hr class="split"><br/> -\-> -->
        
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
        <!--     <tr> -->
        <!--     <td style="padding:20px;width:100%;vertical-align:middle"> -->
        <!--       <heading>News</heading> -->
        <!--       <p> -->
        <!--                         &nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp; [2021.11] Received China National Scholarship. -->
        <!--         <Br> -->
        <!--         &nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp; [2021.05] <a href="http://cvpr2021.thecvf.com/node/184?fbclid=IwAR3zy5xnT4xm3v5uaF8DpUuOadKC0MsgM9sWE39iDivZoSaq0UtgMARFaiA">Outstanding reviewer</a> of <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>. -->
        <!--         <br> -->
        <!--         &nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp; [2021.05] <a href="">HyFRIS-Net</a> accepted to <a href="">TPAMI 2021</a>. -->
        <!--         <br> -->
        <!--         &nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp; [2021.03] <a href="https://arxiv.org/abs/2104.04160">SOLID-Net</a> accepted to <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a> Oral presentation. -->
        <!--         <br> -->
        <!--         &nbsp;&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp; [2021.03] <a href="https://arxiv.org/abs/2104.13602">DeRenderNet</a> accepted to <a href="https://iccp-conference.org/">ICCP 2021</a>. -->
        <!--       </p> -->
        <!--     </td> -->
        <!--   </tr> -->
        <!-- </tbody></table> -->
 
        <!-- <\!-- <hr class="split"><br/> -\-> -->
               
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <br>
              (* indicates equal contribution)
              <p>
                My research interests lie at the intersection of computer vision, computer graphics, and computational photography. Recently, I focus on physics-based computer vision and multimodal in natural language processing, including inferring the physical world (shape, color, light, etc) and linguistic text from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
          <tr onmouseout="eccv22_stop()" onmouseover="eccv22_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='eccv22_image'>
                  <img src='images/eccv22_after_1.png' width="160"></div>
                <img src='images/eccv22_before_1.png' width="160">
              </div>
              <script type="text/javascript">
                function eccv22_start() {
                  document.getElementById('eccv22_image').style.opacity = "1";
                }

                function eccv22_stop() {
                  document.getElementById('eccv22_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Estimating Spatially-Varying Lighting in Urban Scenes with Disentangled Representation</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=UBy9z8wAAAAJ&hl=zh-CN">Jiajun Tang</a>, 
              <strong>Yongjie Zhu</strong>,
              <a href="">Haoyu Wang</a>,
              <a href="">Jun Hoong Chan</a>,
              <a href="">Si Li</a>,
              <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022  &nbsp; <font color="red"><b>(Oral Presentation)</b></font> 
 
              <br>
              <a href="https://ci.idm.pku.edu.cn/Tang_ECCV22a.pdf">[paper]</a>   &nbsp; 
              <a href="data/Tang_ECCV_2022.bib">[bibtex]</a>  &nbsp; 
              <a href="https://github.com/ChemJeff/SOLD-Net/">[project]</a> 
              <p>
                Given a single image and a 2D pixel location, our method can estimate the local lighting that is disentangled into ambient sky light, sun light and lighting-independent local contents.
              </p>
            </td>
          </tr> 

            
          <tr onmouseout="adscvlr_stop()" onmouseover="adscvlr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='adscvlr_image'>
                  <img src='images/adscvlr_after.png' width="160"></div>
                <img src='images/adscvlr_before.png' width="160">
              </div>
              <script type="text/javascript">
                function adscvlr_start() {
                  document.getElementById('adscvlr_image').style.opacity = "1";
                }

                function adscvlr_stop() {
                  document.getElementById('adscvlr_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>AdsCVLR: Commercial Visual-Linguistic Representation Modeling in Sponsored Search</papertitle>
              </a>
              <br>
              <strong>Yongjie Zhu</strong>,
              <a href="">Chunhui Han</a>,
              <a href="">Yuefeng Zhan</a>,
              <a href="">Bochen Pang</a>,
              <a href="">Zhaoju Li</a>,
              <a href="">Hao Sun</a>,
              <a href="">Si Li</a>,
              <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>,
              <a href="https://nanduan.github.io/">Nan Duan</a>,
              <A href="">Ruofei Zhang</a>,
              <a href="">Liangjie Zhang</a>,
              <a href="">Weiwei Deng</a>,
              <a href="">Qi Zhang</a>
              <br>
              <em>ACM International Conference on Multimedia (ACM MM)</em>, 2022  
              <br>
              <a href="https://ci.idm.pku.edu.cn/Zhu_MM22.pdf">[paper]</a>   &nbsp; 
              <a href="data/Zhu_MM_2022.bib">[bibtex]</a>  &nbsp; 
              <a href="https://github.com/microsoft/CommercialAdsDataset/">[project]</a>
              <p>
                We propose a multi-modal relevance modeling approach for sponsored search, and boost the performance via contrastive learning that naturally extends the transformer encoder with the complementary multi-modal inputs. 
              </p>
            </td>
          </tr> 

          <tr onmouseout="face_stop()" onmouseover="face_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='face_image'><img src='images/face_resize.gif'></div>
                <img src='images/face_resize.png'>
              </div>
              <script type="text/javascript">
                function face_start() {
                  document.getElementById('face_image').style.opacity = "1";
                }

                function face_stop() {
                  document.getElementById('face_image').style.opacity = "0";
                }
                face_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Hybrid Face Reflectance, Illumination, and Shape from a Single Image</papertitle>
              </a>
              <br>
              <strong>Yongjie Zhu</strong>,
              <a href="http://lichenpro.com/">Chen Li</a>,
              <a href="">Si Li</a>,
              <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>,
              <a href="https://seng.ust.hk/about/people/faculty/yu-wing-tai">Yu-Wing Tai</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2021 &nbsp; 
              <br>
              <a href="https://ieeexplore.ieee.org/document/9431726">[paper]</a> &nbsp;  
              <a href="data/Zhu_TPAMI_2021.bib">[bibtex]</a> &nbsp; 
              <a href="https://youtu.be/USTbDW6MnEA">[video]</a> &nbsp; 
              <p></p>
              <p>
                We proposed a self-supervised deep learning framework that can estimate the hybrid reflection model and detailed normal of the human face. The proposed hybrid reflectance and illumination representation ensures the photo-realistic face reconstruction.
              </p>
            </td>
          </tr> 
 
          <tr onmouseout="solid_stop()" onmouseover="solid_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='solid_image'>
                  <img src='images/solid_after.png' width="160"></div>
                <img src='images/solid_before.png' width="160">
              </div>
              <script type="text/javascript">
                function solid_start() {
                  document.getElementById('solid_image').style.opacity = "1";
                }

                function solid_stop() {
                  document.getElementById('solid_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Spatially-Varying Outdoor Lighting Estimation from Intrinsics</papertitle>
              </a>
              <br>
              <strong>Yongjie Zhu</strong>,
              <a href="https://www.zhangyinda.com/">Yinda Zhang</a>,
              <a href="">Si Li</a>,
              <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021 &nbsp; <font color="red"><b>(Oral Presentation)</b></font> 
              <br> 
              <a href="https://arxiv.org/abs/2104.04160">[arXiv]</a>   &nbsp; 
              <a href="data/Zhu_CVPR_2021.bib">[bibtex]</a> &nbsp; 
              <a href="https://youtu.be/O1M1k6JncoA">[video]</a> &nbsp; 
              <a href="https://drive.google.com/file/d/1_mzhuRQyv1jwTmTNh2UnuEr-0nMkZgPg/view?usp=sharing">[poster]</a> 
              <p></p>
              <p>
              Collecting high quality paired intrinsic and lighting data in a virtual city lets you train a model that estimates spatially-varying lighting from a single outdoor image.
              </p>
            </td>
          </tr> 
            
          <tr onmouseout="derender_stop()" onmouseover="derender_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='derender_image'>
                  <img src='images/derendernet_after.png' width="160"></div>
                <img src='images/derendernet_before.png' width="160">
              </div>
              <script type="text/javascript">
                function derender_start() {
                  document.getElementById('derender_image').style.opacity = "1";
                }

                function derender_stop() {
                  document.getElementById('derender_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:0px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>DeRenderNet: Intrinsic Image Decomposition of Urban Scenes with Shape-(In)dependent Shading Rendering</papertitle>
              </a>
              <br>
              <strong>Yongjie Zhu</strong>,
              <a href="https://scholar.google.com/citations?user=UBy9z8wAAAAJ&hl=zh-CN">Jiajun Tang</a>,
              <a href="">Si Li</a>,
              <a href="http://alumni.media.mit.edu/~shiboxin/index.html">Boxin Shi</a>
              <br>
              <em>International Conference on Computational Photography (ICCP)</em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2104.13602">[arXiv]</a>   &nbsp; 
              <a href="data/Zhu_ICCP_2021.bib">[bibtex]</a>
              <p>
                Decomposing a single RGB image into its reflectance, shading (caused by direct lighting), and shadow (caused by occlusion) images.
              </p>
            </td>
          </tr> 

        </tbody></table>


        <!-- <hr class="split"><br/> -->
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="97%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
              <img src="images/cvpr_logo.png" alt="clean-usnob" width="100" height="40">
            </td>
            <td width="75%" valign="middle">
                Conference Reviewer, <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>     
            </td>
          </tr>
          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
              <img src="images/springer_logo.png" alt="clean-usnob" width="160" height="40">
            </td>
            <td width="75%" valign="middle">
              Journal Reviewer, <a href="https://www.springer.com/journal/11263/">IJCV 2020, IJCV 2022</a>               
            </td>
          </tr>
          </tbody>
        </table>
       
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Current and Past Affiliations</heading>
            </td>
          </tr>
        </tbody></table>        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="10%" valign="middle">
              <a href="https://www.alibabagroup.com/"><img src="media/logo-alibaba.png" width="78"></a>
            </td>

            <td width="10%" valign="middle">
              <a href="https://www.bupt.edu.cn/"><img src="media/bupt_logo.png" width="75"></a>
            </td>
            <td width="10%" valign="middle">
              <a href="https://www.microsoft.com/"><img src="media/microsoft_logo1.png" width="75"></a>
            </td>

            <td width="10%" valign="middle">
              <a href="https://www.wechat.com/"><img src="media/wechat_logo.png" width="75"></a>
            </td>
            <td width="10%" valign="middle">
              <a href="https://ci.idm.pku.edu.cn/"><img src="media/pku_logo.png" width="75"></a>
            </td>
            <td width="10%" valign="middle">
              <a href="https://open.youtu.qq.com/"><img src="media/youtu_logo1.png" width="75"></a>
            </td>
      </td>      
    </tr>
    </table> 
    
    <hr class="split"><br/>
        
        <!-- <table width="97%" align="center" border="0" cellpadding="20"><tbody> -->
        <!--   <tr> -->
        <!--     <td style="padding:10px;width:25%;vertical-align:middle"> -->
        <!--       <body> -->
        <!--         <\!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=320&t=m&d=4G1UZkJRhwxNfETjjT_LOh2OxmkfIWo_k2YfL9xfO8A'></script> -\-> -->
        <!--         <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=320&t=tt&d=4G1UZkJRhwxNfETjjT_LOh2OxmkfIWo_k2YfL9xfO8A"></script> -->
        <!--       </body>               -->
        <!--     </td> -->
        <!--     <td width="25%" valign="middle"> -->
        <!--         Homepage of Yongjie Zhu [朱勇杰] <br> © Yongjie Zhu. All Rights Reserved.     -->
        <!--     </td> -->
 
        <!--   </tr> -->
        <!-- </tbody></table> -->
    
    <!--           CopyRight-->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr>
          <td width=30% align="center">
            <script type="text/javascript" id="clustrmaps"
                    src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=4G1UZkJRhwxNfETjjT_LOh2OxmkfIWo_k2YfL9xfO8A"></script>
          </td>
          <td style="padding:10px">
            <br>
            <p style="text-align:right;">Homepage of Yongjie Zhu [朱勇杰] <br> © Yongjie Zhu. All Rights Reserved. </a></p>
          </td>
        </tr>
      </tbody>
    </table>

      </td>
    </tr>
  </table>
</body>

</html>
